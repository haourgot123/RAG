{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMXA0/F83PUa5QQNs60jHlS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a2e79d1fbe7645e5a68c66ed80bc792b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9865785307ac4ed085fea4d5a90f637b","IPY_MODEL_f2abd382613342daa49893c6d26119ac","IPY_MODEL_25405a8804e6454d96a0a55a061e6240"],"layout":"IPY_MODEL_edce08f995744c749a26bf13f39bac7d"}},"9865785307ac4ed085fea4d5a90f637b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc36b675a1d046649eb5458defba3b5c","placeholder":"​","style":"IPY_MODEL_7bd8b04d2e9144f79a45de14c7f449bd","value":"Map: 100%"}},"f2abd382613342daa49893c6d26119ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_adc0494ff8ce452a9829d3da4e7785ed","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13980221320a4759acb73cff938d078c","value":10}},"25405a8804e6454d96a0a55a061e6240":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_714b078fb30f4148981b8879015dc759","placeholder":"​","style":"IPY_MODEL_6e37e76fc02f48ec9a852c741329b2d5","value":" 10/10 [00:00&lt;00:00, 100.77 examples/s]"}},"edce08f995744c749a26bf13f39bac7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc36b675a1d046649eb5458defba3b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bd8b04d2e9144f79a45de14c7f449bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adc0494ff8ce452a9829d3da4e7785ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13980221320a4759acb73cff938d078c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"714b078fb30f4148981b8879015dc759":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e37e76fc02f48ec9a852c741329b2d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02eff6062b8849dda52c6a42e777c71d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d85d3bfd12d4b399217ad99ba9b736c","IPY_MODEL_c87edd2f49a44231829f7126f285dba9","IPY_MODEL_77a0e01ee8e94a499bfccff20c3a7404"],"layout":"IPY_MODEL_14c8599dd0a14c4b8f9a6e262510c3f1"}},"5d85d3bfd12d4b399217ad99ba9b736c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb380112e07a4047a009407061bfd0f8","placeholder":"​","style":"IPY_MODEL_f8945db4fbca40c38d172bec76395ab9","value":"Map (num_proc=2): 100%"}},"c87edd2f49a44231829f7126f285dba9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28c7aa97425749f7822cbf728ed6ac14","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15dc22cd9a134437b191857f39886ead","value":10}},"77a0e01ee8e94a499bfccff20c3a7404":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5245b0a4eefb4b38aee2b901f60ce331","placeholder":"​","style":"IPY_MODEL_2236771a9be84604bf7b2f40870e4489","value":" 10/10 [00:00&lt;00:00,  6.56 examples/s]"}},"14c8599dd0a14c4b8f9a6e262510c3f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb380112e07a4047a009407061bfd0f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8945db4fbca40c38d172bec76395ab9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28c7aa97425749f7822cbf728ed6ac14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15dc22cd9a134437b191857f39886ead":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5245b0a4eefb4b38aee2b901f60ce331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2236771a9be84604bf7b2f40870e4489":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f5b51f6350748c5a922b802a239c772":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e02d98d2e1a945c48fd4e62d0e0301f2","IPY_MODEL_886e77424f354f28bdcbd0dcc982db49","IPY_MODEL_46172178ec2e4e849b8a390c3e58ddc2","IPY_MODEL_c9fb8def1231404d8331f97eaf72a1c0"],"layout":"IPY_MODEL_8cb7c56f0b9c4e8890982a19cd57a854"}},"b34ae67c35674a60b7581283c5a3631f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3ab260bc832438984400b7e8e9b3c59","placeholder":"​","style":"IPY_MODEL_c66b1f09405b4cc0a237351172186cc4","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"e897aa8c6d5a44ada2b3a46de6900765":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_c8622116b9e8481b8c22a688f8b8a0bc","placeholder":"​","style":"IPY_MODEL_c16986902e264d16b3306fb29c19a0eb","value":""}},"339d2f1b8af64d478df8d3b2a06d7a85":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_53621f864e4b43948273d343c3a77501","style":"IPY_MODEL_cfa28033dcb042698d55e092fa07b32f","value":true}},"4abced0c26c84246a97979af38e66cec":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_ae841747590f4ec8a5ac9648fbd7d213","style":"IPY_MODEL_a00ec12ca0bd426eb1f67f6be1ef33dc","tooltip":""}},"8ec32ce878924bb8ab18f7db2b9676be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c74dc10abc57483ab0e8e69cda2d3b05","placeholder":"​","style":"IPY_MODEL_f15b4df87e5e485dbf5274b483317f1a","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"8cb7c56f0b9c4e8890982a19cd57a854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"e3ab260bc832438984400b7e8e9b3c59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c66b1f09405b4cc0a237351172186cc4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8622116b9e8481b8c22a688f8b8a0bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c16986902e264d16b3306fb29c19a0eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53621f864e4b43948273d343c3a77501":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfa28033dcb042698d55e092fa07b32f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae841747590f4ec8a5ac9648fbd7d213":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a00ec12ca0bd426eb1f67f6be1ef33dc":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"c74dc10abc57483ab0e8e69cda2d3b05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f15b4df87e5e485dbf5274b483317f1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1fa55c6885a408ea4dc8dbff4ab34e1":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f246963478b64f459f119bbc0559a3a1","placeholder":"​","style":"IPY_MODEL_6d99bc2571824111b472b98897d022ea","value":"Connecting..."}},"f246963478b64f459f119bbc0559a3a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d99bc2571824111b472b98897d022ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e02d98d2e1a945c48fd4e62d0e0301f2":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_764f0e99dfda4825984846f1b2b3547d","placeholder":"​","style":"IPY_MODEL_625b3a075c1a4174a5ef44d41c7191f5","value":"Token is valid (permission: fineGrained)."}},"886e77424f354f28bdcbd0dcc982db49":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85d881920e3d436196de68af9190c4d1","placeholder":"​","style":"IPY_MODEL_8b1df4222edf401cbcd4cf75d7bab1ef","value":"Your token has been saved in your configured git credential helpers (store)."}},"46172178ec2e4e849b8a390c3e58ddc2":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6238c1a07be4777bc43a0482c8e0acd","placeholder":"​","style":"IPY_MODEL_c1201f0a85c84d5195767c1c48c37cd3","value":"Your token has been saved to /root/.cache/huggingface/token"}},"c9fb8def1231404d8331f97eaf72a1c0":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a070a2e75b44c3d85d8c557137631ca","placeholder":"​","style":"IPY_MODEL_cc49199f5da949ac881ab90e4c1af25a","value":"Login successful"}},"764f0e99dfda4825984846f1b2b3547d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"625b3a075c1a4174a5ef44d41c7191f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85d881920e3d436196de68af9190c4d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1df4222edf401cbcd4cf75d7bab1ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6238c1a07be4777bc43a0482c8e0acd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1201f0a85c84d5195767c1c48c37cd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a070a2e75b44c3d85d8c557137631ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc49199f5da949ac881ab90e4c1af25a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Tải các package"],"metadata":{"id":"VY_NfD-IbFDn"}},{"cell_type":"code","source":["!pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yNSknC0BjNtO","executionInfo":{"status":"ok","timestamp":1730075805603,"user_tz":-420,"elapsed":13898,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"8f573d21-978d-4551-abc3-675b8fce2805"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/trl.git\n","  Cloning https://github.com/huggingface/trl.git to /tmp/pip-req-build-lyqirsph\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-lyqirsph\n","  Resolved https://github.com/huggingface/trl.git to commit ea7a1be92c1262b95a57c55a6602a9251ad4afa6\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: unsloth in /usr/local/lib/python3.10/dist-packages (2024.10.7)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.0)\n"]}]},{"cell_type":"code","source":["!pip install -q dataset"],"metadata":{"id":"iLkOc6jTgZdo","executionInfo":{"status":"ok","timestamp":1730075810173,"user_tz":-420,"elapsed":4613,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%%capture\n","import torch\n","major_version, minor_version = torch.cuda.get_device_capability()\n","# Must install separately since Colab has torch 2.2.1, which breaks packages\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","if major_version >= 8:\n","    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n","    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n","else:\n","    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n","    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n","pass"],"metadata":{"id":"UxKMKl52a6bw","executionInfo":{"status":"ok","timestamp":1730075836669,"user_tz":-420,"elapsed":26511,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Lựa chọn mô hình mistral 7B instruct"],"metadata":{"id":"y4ccKleFa6Dg"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"xcqNhiNlqi_i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730075882287,"user_tz":-420,"elapsed":45666,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"5ea68174-644c-488b-be79-5bcf1f9eb64f"},"outputs":[{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","==((====))==  Unsloth 2024.10.7: Fast Mistral patching. Transformers = 4.46.0.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.5.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 512 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/mistral-7b-bnb-4bit\",\n","    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n","    \"unsloth/llama-2-7b-bnb-4bit\",\n","    \"unsloth/llama-2-13b-bnb-4bit\",\n","    \"unsloth/codellama-34b-bnb-4bit\",\n","    \"unsloth/tinyllama-bnb-4bit\",\n","    \"unsloth/gemma-7b-bnb-4bit\", # New Google 6 trillion tokens model 2.5x faster!\n","    \"unsloth/gemma-2b-bnb-4bit\",\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"markdown","source":["# Thêm vào LoRA Adapter và chúng tả chỉ cập nhật từ 1 đến 10% trong số của mô hình"],"metadata":{"id":"eb0GOIwvbczR"}},{"cell_type":"markdown","source":["🔥 Tham số r = 8, 16, 32,... với các tác vụ càng phức tạp thì tăng tham số này lên (thường sẽ là đến 128)\n","\n","🔥 LoRA alpha hường sử dụng 16"],"metadata":{"id":"lbR_I-asb0dD"}},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 8, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    use_gradient_checkpointing = True,\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ScqT3OqMbVSo","executionInfo":{"status":"ok","timestamp":1730075888167,"user_tz":-420,"elapsed":5884,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"4a1dbfc0-cbff-4aca-ab73-b6ca5f5765d7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.10.7 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}]},{"cell_type":"markdown","source":["# Chuẩn bị dữ liệu\n","\n","Chúng ta sẽ chọn `chatml` để làm chuẩn finetune. `ChatML` sẽ có định dạng như sau:\n","\n","```\n","<|im_start|>system\n","You are a helpful assistant.<|im_end|>\n","<|im_start|>user\n","What's the capital of France?<|im_end|>\n","<|im_start|>assistant\n","Paris.\n","```\n","\n","**[NOTE}**: Chúng ta sẽ sử dụng `get_chat_template` để lấy đúng template. Unsolothl hỗ trợ các chuẩn bao gồm : `zephyr`, `chatml`, `mistral`, `llama`, `alpaca`, `vicuna`, `vicuna_old`.\\\\\n","\n"],"metadata":{"id":"KvEv7sR-cVf3"}},{"cell_type":"code","source":["from unsloth.chat_templates import get_chat_template\n","\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template = \"chatml\",\n","    mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"},\n","    map_eos_token = True\n",")\n","\n","def formating_prompts_func(examples):\n","  convos = examples['conversations']\n","  texts = [tokenizer.apply_chat_template(convo , tokenize = False, add_generation_prompt = False) for convo in convos]\n","  return {'text' : texts,}\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset('qnguyen3/demo_faq', split = 'train')\n","dataset = dataset.map(formating_prompts_func, batched = True, )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["a2e79d1fbe7645e5a68c66ed80bc792b","9865785307ac4ed085fea4d5a90f637b","f2abd382613342daa49893c6d26119ac","25405a8804e6454d96a0a55a061e6240","edce08f995744c749a26bf13f39bac7d","bc36b675a1d046649eb5458defba3b5c","7bd8b04d2e9144f79a45de14c7f449bd","adc0494ff8ce452a9829d3da4e7785ed","13980221320a4759acb73cff938d078c","714b078fb30f4148981b8879015dc759","6e37e76fc02f48ec9a852c741329b2d5"]},"id":"nW5Maa-4bwD_","executionInfo":{"status":"ok","timestamp":1730075890448,"user_tz":-420,"elapsed":2290,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"8db6c26d-1b0a-4574-d4b2-f89b276061a4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: Will map <|im_end|> to EOS = </s>.\n","You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/10 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2e79d1fbe7645e5a68c66ed80bc792b"}},"metadata":{}}]},{"cell_type":"code","source":["dataset['text'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"Cn-83fJvgLTp","executionInfo":{"status":"ok","timestamp":1730075890449,"user_tz":-420,"elapsed":107,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"83c046b6-a794-4156-a24f-0df3342d810c"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|im_start|>user\\nWhat is VinaLLaMA?<|im_end|>\\n<|im_start|>assistant\\nVinaLLaMA is an open-source, state-of-the-art Large Language Model for the Vietnamese language.<|im_end|>\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# Kiểm tra 5 element để xem chatml hoạt động"],"metadata":{"id":"GSZMmQxig_G6"}},{"cell_type":"code","source":["dataset[5]['conversations']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"orev9caQgw2Y","executionInfo":{"status":"ok","timestamp":1730075890449,"user_tz":-420,"elapsed":105,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"5b4e4b23-d628-4641-8193-dc1aa0ccfc62"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'from': 'human',\n","  'value': 'How does VinaLLaMA contribute to the Vietnamese AI landscape?'},\n"," {'from': 'gpt',\n","  'value': 'VinaLLaMA marks a significant advancement in the Vietnamese AI landscape and offers a versatile resource for various applications.'}]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["dataset[5]['text']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"7qEAZ2CqhKZb","executionInfo":{"status":"ok","timestamp":1730075890459,"user_tz":-420,"elapsed":113,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"e3ce3f11-d989-4bbe-c9d3-22aca9836557"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<|im_start|>user\\nHow does VinaLLaMA contribute to the Vietnamese AI landscape?<|im_end|>\\n<|im_start|>assistant\\nVinaLLaMA marks a significant advancement in the Vietnamese AI landscape and offers a versatile resource for various applications.<|im_end|>\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# Nếu muốn tự tạo template riêng cho bản thấn mình"],"metadata":{"id":"DYYQXlpZh6_g"}},{"cell_type":"code","source":["unsloth_template = \\\n","    \"{{ bos_token }}\"\\\n","    \"{{ 'You are a helpful assistant to the user\\n' }}\"\\\n","    \"{% endif %}\"\\\n","    \"{% for message in messages %}\"\\\n","        \"{% if message['role'] == 'user' %}\"\\\n","            \"{{ '>>> User: ' + message['content'] + '\\n' }}\"\\\n","        \"{% elif message['role'] == 'assistant' %}\"\\\n","            \"{{ '>>> Assistant: ' + message['content'] + eos_token + '\\n' }}\"\\\n","        \"{% endif %}\"\\\n","    \"{% endfor %}\"\\\n","    \"{% if add_generation_prompt %}\"\\\n","        \"{{ '>>> Assistant: ' }}\"\\\n","    \"{% endif %}\"\n","unsloth_eos_token = \"eos_token\"\n","\n","if False:\n","  print('Done')\n","  tokenizer = get_chat_template(\n","        tokenizer,\n","        chat_template = (unsloth_template, unsloth_eos_token,), # You must provide a template and EOS token\n","        mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"}, # ShareGPT style\n","        map_eos_token = True, # Maps <|im_end|> to </s> instead\n","    )"],"metadata":{"id":"LdEBu9ahhNlV","executionInfo":{"status":"ok","timestamp":1730075890459,"user_tz":-420,"elapsed":112,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Train model"],"metadata":{"id":"zj8hbO--iBdS"}},{"cell_type":"code","source":["\n","from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2, # Nếu có nhiều GPU, thì nó sẽ hỗ trợ chia các batch cho từng GPU\n","        gradient_accumulation_steps = 4, # Tích luỹ Gradient cứ 4 step 1 lần\n","        warmup_steps = 5,\n","        num_train_epochs = 10,\n","        learning_rate = 2e-4,\n","        fp16 = not torch.cuda.is_bf16_supported(),\n","        bf16 = torch.cuda.is_bf16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"cosine\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["02eff6062b8849dda52c6a42e777c71d","5d85d3bfd12d4b399217ad99ba9b736c","c87edd2f49a44231829f7126f285dba9","77a0e01ee8e94a499bfccff20c3a7404","14c8599dd0a14c4b8f9a6e262510c3f1","bb380112e07a4047a009407061bfd0f8","f8945db4fbca40c38d172bec76395ab9","28c7aa97425749f7822cbf728ed6ac14","15dc22cd9a134437b191857f39886ead","5245b0a4eefb4b38aee2b901f60ce331","2236771a9be84604bf7b2f40870e4489"]},"id":"kZk2T0-WhjdN","executionInfo":{"status":"ok","timestamp":1730075892014,"user_tz":-420,"elapsed":1666,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"145131c1-7f7a-4b22-8204-07593c64a184"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/10 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02eff6062b8849dda52c6a42e777c71d"}},"metadata":{}}]},{"cell_type":"code","source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fjn0WRm2ivsC","executionInfo":{"status":"ok","timestamp":1730075892015,"user_tz":-420,"elapsed":13,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"05de0fca-5481-4cac-854b-9cf8fcefd648"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","4.547 GB of memory reserved.\n"]}]},{"cell_type":"code","source":["trainer_stats = trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":704},"id":"F6Y4rN86i0QY","executionInfo":{"status":"ok","timestamp":1730076040262,"user_tz":-420,"elapsed":148255,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"b1c40a43-2008-4686-983c-e63f68185f1c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 10 | Num Epochs = 10\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 10\n"," \"-____-\"     Number of trainable parameters = 20,971,520\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.5"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20241028_003951-e7oo84oe</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/nguyenhao28032003-h-c-vi-n-c-ng-ngh-b-u-ch-nh-vi-n-th-ng/huggingface/runs/e7oo84oe' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/nguyenhao28032003-h-c-vi-n-c-ng-ngh-b-u-ch-nh-vi-n-th-ng/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/nguyenhao28032003-h-c-vi-n-c-ng-ngh-b-u-ch-nh-vi-n-th-ng/huggingface' target=\"_blank\">https://wandb.ai/nguyenhao28032003-h-c-vi-n-c-ng-ngh-b-u-ch-nh-vi-n-th-ng/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/nguyenhao28032003-h-c-vi-n-c-ng-ngh-b-u-ch-nh-vi-n-th-ng/huggingface/runs/e7oo84oe' target=\"_blank\">https://wandb.ai/nguyenhao28032003-h-c-vi-n-c-ng-ngh-b-u-ch-nh-vi-n-th-ng/huggingface/runs/e7oo84oe</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10/10 00:36, Epoch 8/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>4.362300</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>7.364700</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>8.044400</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>6.212200</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>5.630200</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.309900</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.868900</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.318700</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.660300</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.538000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HlVtp912i9Uk","executionInfo":{"status":"ok","timestamp":1730076067509,"user_tz":-420,"elapsed":432,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"1b93b23a-ca6d-4edd-9b4d-c62abaac568e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["142.5106 seconds used for training.\n","2.38 minutes used for training.\n","Peak reserved memory = 5.043 GB.\n","Peak reserved memory for training = 0.496 GB.\n","Peak reserved memory % of max memory = 34.194 %.\n","Peak reserved memory for training % of max memory = 3.363 %.\n"]}]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"O-mvxkAnko3q"}},{"cell_type":"code","source":["from unsloth.chat_templates import get_chat_template\n","\n","tokenizer = get_chat_template(\n","    tokenizer,\n","    chat_template = \"chatml\", # Supports zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, unsloth\n","    mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"}, # ShareGPT style\n","    map_eos_token = True, # Maps <|im_end|> to </s> instead\n",")\n","\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","messages = [\n","    {\"from\": \"human\", \"value\": \"Can you tell me how many tokens were VinaLlama trained on?\"},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize = True,\n","    add_generation_prompt = True, # Phải add dòng này vào cho việc GEN\n","    return_tensors = \"pt\",\n",").to(\"cuda\")\n","\n","print(inputs)\n","\n","outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True)\n","tokenizer.batch_decode(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C66E_2hKkcLM","executionInfo":{"status":"ok","timestamp":1730076831528,"user_tz":-420,"elapsed":3536,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"a7e7fb35-926f-423d-fc3f-854dc7b70111"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[  523, 28766,   321, 28730,  2521, 28766, 28767,  1838,    13,  6325,\n","           368,  1912,   528,   910,  1287, 16246,   654,   550,  1380, 28758,\n","         28714,  2786, 10898,   356, 28804,     2,    13, 28789, 28766,   321,\n","         28730,  2521, 28766, 28767,   489, 11143,    13]], device='cuda:0')\n"]},{"output_type":"execute_result","data":{"text/plain":["['<|im_start|>user\\nCan you tell me how many tokens were VinaLlama trained on?<|im_end|>\\n<|im_start|>assistant\\nSure, VinaLLaMA was trained on 1.5 trillion tokens.<|im_end|>']"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["print(tokenizer.batch_decode(outputs)[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aeZBlDSCmkk9","executionInfo":{"status":"ok","timestamp":1730076900385,"user_tz":-420,"elapsed":16,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"8af0220b-ec25-4cfe-faf4-25fdb8d568ff"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["<|im_start|>user\n","Can you tell me how many tokens were VinaLlama trained on?<|im_end|>\n","<|im_start|>assistant\n","Sure, VinaLLaMA was trained on 1.5 trillion tokens.<|im_end|>\n"]}]},{"cell_type":"markdown","source":["# Chúng ta có thể dùng text stream để hiện thị các từ GEN ra lần lượt thay vì đợi mô hình GEN xong mới in ra"],"metadata":{"id":"ovIDwCaxnyCg"}},{"cell_type":"code","source":["FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","messages = [\n","    {\"from\": \"human\", \"value\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n","]\n","inputs = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize = True,\n","    add_generation_prompt = True, # Must add for generation\n","    return_tensors = \"pt\",\n",").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128, use_cache = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A83oFniLnnYZ","executionInfo":{"status":"ok","timestamp":1730076936617,"user_tz":-420,"elapsed":1924,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"35ca2290-aefc-41d1-8c1b-edee173b0f4d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["<|im_start|>user\n","Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,<|im_end|>\n","<|im_start|>assistant\n","The next number in the sequence is 13.<|im_end|>\n"]}]},{"cell_type":"markdown","source":["# @SAVING AND LOADING FINETUNE MODEL"],"metadata":{"id":"S5C1n5bwobQp"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["3f5b51f6350748c5a922b802a239c772","b34ae67c35674a60b7581283c5a3631f","e897aa8c6d5a44ada2b3a46de6900765","339d2f1b8af64d478df8d3b2a06d7a85","4abced0c26c84246a97979af38e66cec","8ec32ce878924bb8ab18f7db2b9676be","8cb7c56f0b9c4e8890982a19cd57a854","e3ab260bc832438984400b7e8e9b3c59","c66b1f09405b4cc0a237351172186cc4","c8622116b9e8481b8c22a688f8b8a0bc","c16986902e264d16b3306fb29c19a0eb","53621f864e4b43948273d343c3a77501","cfa28033dcb042698d55e092fa07b32f","ae841747590f4ec8a5ac9648fbd7d213","a00ec12ca0bd426eb1f67f6be1ef33dc","c74dc10abc57483ab0e8e69cda2d3b05","f15b4df87e5e485dbf5274b483317f1a","e1fa55c6885a408ea4dc8dbff4ab34e1","f246963478b64f459f119bbc0559a3a1","6d99bc2571824111b472b98897d022ea","e02d98d2e1a945c48fd4e62d0e0301f2","886e77424f354f28bdcbd0dcc982db49","46172178ec2e4e849b8a390c3e58ddc2","c9fb8def1231404d8331f97eaf72a1c0","764f0e99dfda4825984846f1b2b3547d","625b3a075c1a4174a5ef44d41c7191f5","85d881920e3d436196de68af9190c4d1","8b1df4222edf401cbcd4cf75d7bab1ef","f6238c1a07be4777bc43a0482c8e0acd","c1201f0a85c84d5195767c1c48c37cd3","4a070a2e75b44c3d85d8c557137631ca","cc49199f5da949ac881ab90e4c1af25a"]},"id":"nwKf16zSqHCZ","executionInfo":{"status":"ok","timestamp":1730077851274,"user_tz":-420,"elapsed":34,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"c71c3e94-3c35-4c09-c4ab-7437ff77b2da"},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f5b51f6350748c5a922b802a239c772"}},"metadata":{}}]},{"cell_type":"markdown","source":["**[NOTE]** : Lưu ý mở chế độ write trong phần `Access Token` để có thể push được model lên hugging-face"],"metadata":{"id":"dXNZ_Rw1sCWu"}},{"cell_type":"code","source":["model.save_pretrained(\"unsloth_vinallama\") # Local saving\n","model.push_to_hub(\"HaoNN/unsloth_vinallama\") # Online saving"],"metadata":{"id":"0exL0T6HoSCn","executionInfo":{"status":"ok","timestamp":1730080412416,"user_tz":-420,"elapsed":5153,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["# Saving to float15 for VLLM\n","\n","Hỗ trợ lưu trực tiếp `float16`. Chọn `merge_16bit` cho float16 và `merge_4bit` cho int4."],"metadata":{"id":"WqFG43hIuk22"}},{"cell_type":"code","source":["# # Merge to 16bit\n","# model.save_pretrained_merged(\"unsloth_model\", tokenizer, save_method = \"merged_16bit\",)\n","model.push_to_hub_merged(\"HaoNN/unsloth_vinallama_model\", tokenizer, save_method = \"merged_16bit\")\n","\n","# # Merge to 4bit\n","# if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n","# if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n","\n","# # Just LoRA adapters\n","# if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n","# if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WjUH-0Txs3wj","executionInfo":{"status":"ok","timestamp":1730081159350,"user_tz":-420,"elapsed":731442,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"4d1b54ae-c542-4a0f-9296-06a704a2f6b9"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: Will remove a cached repo with size 1.2K\n","100%|██████████| 32/32 [03:26<00:00,  6.44s/it]\n"]}]},{"cell_type":"code","source":["# Save to 8bit Q8_0\n","if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n","\n","# Save to 16bit GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n","\n","# Save to q4_k_m GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")"],"metadata":{"id":"Ttl6JyqVvLsx","executionInfo":{"status":"ok","timestamp":1730081677581,"user_tz":-420,"elapsed":411,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"C9lo9h82w3ix","executionInfo":{"status":"aborted","timestamp":1730079341539,"user_tz":-420,"elapsed":22,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":null,"outputs":[]}]}