{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1U5FbEfCyMZt6zxvqgqTY-nuo7Y-o_djq","authorship_tag":"ABX9TyM3wmZOR2fh/CiS5jp9hBNx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"cab83240202b41eea376a511ef7f4199":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_838b873ab8124dde888d5f18658371c7","IPY_MODEL_e26eec2557cd4fe98d77b078a32cc2b7","IPY_MODEL_2373325ca01c42d5aacf48d00c830aca"],"layout":"IPY_MODEL_6f64822857cc428da4a5adbb2dc610cf"}},"838b873ab8124dde888d5f18658371c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eacb700bf9c446fba04b01bf8596c273","placeholder":"​","style":"IPY_MODEL_1ea59cb4c4034f0f95658a0e990993bf","value":"Generating train split: "}},"e26eec2557cd4fe98d77b078a32cc2b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_092716b7e4b9451f8cb108042e9801db","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe24851f00dc45f5a1acec062c1e5bbc","value":1}},"2373325ca01c42d5aacf48d00c830aca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0850909617b94bde80ce36644ba52a1b","placeholder":"​","style":"IPY_MODEL_ca98787ce6a44e809a3da6ad7e584021","value":" 100/0 [00:00&lt;00:00, 634.82 examples/s]"}},"6f64822857cc428da4a5adbb2dc610cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eacb700bf9c446fba04b01bf8596c273":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ea59cb4c4034f0f95658a0e990993bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"092716b7e4b9451f8cb108042e9801db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"fe24851f00dc45f5a1acec062c1e5bbc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0850909617b94bde80ce36644ba52a1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca98787ce6a44e809a3da6ad7e584021":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Tải các package cần thiết"],"metadata":{"id":"4ziAlRh-QoGR"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPdBma_iQjWZ","executionInfo":{"status":"ok","timestamp":1730054198727,"user_tz":-420,"elapsed":54288,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"eae8a9c1-fb35-4308-8b43-5360b08e6ad2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.0/607.0 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.0/408.0 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install --quiet -U langchain chromadb langchain-openai pypdf gradio datasets langchain_community"]},{"cell_type":"code","source":["# Tải groq\n","!pip install -q groq"],"metadata":{"id":"wANWzpJ2i5ep","executionInfo":{"status":"ok","timestamp":1730058914463,"user_tz":-420,"elapsed":7194,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["# Load và Split documents"],"metadata":{"id":"xHINw3f7TjlO"}},{"cell_type":"code","source":["from langchain import hub\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.vectorstores import Chroma\n","from langchain_openai import OpenAIEmbeddings\n","from langchain_community.document_loaders import PyPDFLoader\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=50)\n","loader = PyPDFLoader(\"/content/drive/MyDrive/Colab Notebooks/Buổi 7/vinallama.pdf\")\n","splits = loader.load_and_split(text_splitter)"],"metadata":{"id":"98nr9apJQwFy","executionInfo":{"status":"ok","timestamp":1730055312131,"user_tz":-420,"elapsed":773,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Kiểm tra các Documents được tạo ra"],"metadata":{"id":"4Yz8Ws2oVsSP"}},{"cell_type":"code","source":["splits[20].page_content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"J3S6sOgTTx6e","executionInfo":{"status":"ok","timestamp":1730055408118,"user_tz":-420,"elapsed":390,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"a6ab3824-8774-4479-c26d-94d465fad58d"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'performance assessment. This methodology employs an ELO ranking system, traditionally used in\\nchess and other competitive games, to rate the models. Such a system offers a dynamic and rela-\\ntive measure of model performance, allowing for a nuanced and comparative analysis of each model’s\\nproficiency in handling a variety of tasks and instructions within the benchmark. This ELO-based\\nevaluation provides a clear and quantifiable ranking of the models, reflecting their effectiveness and\\nadaptability in the context of the Vietnamese language and the specific challenges presented by the\\nVicuna Benchmark.\\nIn our Vicuna Benchmark evaluation, responses from models were assessed using a detailed five-\\npoint scale: 0 (’very bad’), 1 (’bad’), 2 (’ok’), 3 (’good’), and 4 (’very good’). This granular scoring\\nsystem allows for an in-depth evaluation of the quality of each model’s response. The final ELO score\\nfor each model is computed by aggregating these individual ratings, providing a holistic measure of a\\n7'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# Tạo prompt cho synthetic data"],"metadata":{"id":"Hdd1HqaMWDTl"}},{"cell_type":"code","source":["synthetic_prompt = \"\"\"\n","Bạn sẽ được cung cấp với một đoạn văn bản. Nhiệm vụ của bạn là hãy dựa trên nội dung này và tạo ra 20 cặp câu hỏi theo dạng FAQ mà một người bình thường sẽ hỏi:\n","---CONTEXT---\n","{context}\n","---END---\n","Bạn hãy tạo ra 10 cặp câu hỏi bằng Tiếng Việt theo dạng FAQ mà một người bình thường sẽ hỏi với format như sau:\n","---FORMAT INSTRUCTION---\n","Question:\n","<question1>\n","Answer:\n","<answer1>\n","\n","Question:\n","<question2>\n","Answer:\n","<answer2>\n","... do this 10 times\n","---END---\n","Now, let's start\n","---START---\n","\"\"\""],"metadata":{"id":"uA267yo4VWXx","executionInfo":{"status":"ok","timestamp":1730058681510,"user_tz":-420,"elapsed":394,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["splits[0].page_content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"fH-9lY73iHjX","executionInfo":{"status":"ok","timestamp":1730058713806,"user_tz":-420,"elapsed":431,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"a010d510-b79c-4c33-fe9b-5b193994e9ca"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'VinaLLaMA: LLaMA-based Vietnamese Foundation Model\\nQuan Nguyen∗, Huy Pham and†Dung Dao‡\\nDecember 19, 2023\\nAbstract\\nIn this technical report, we present VinaLLaMA, an open-weight, state-of-the-art (SOTA)\\nLarge Language Model for the Vietnamese language, built upon LLaMA-2 with an additional\\n800 billion trained tokens. VinaLLaMA not only demonstrates fluency in Vietnamese but also\\nexhibits a profound understanding of Vietnamese culture, making it a truly indigenous model.\\nVinaLLaMA-7B-chat, trained on 1 million high-quality synthetic samples, achieves SOTA results\\non key benchmarks, including VLSP, VMLU, and Vicuna Benchmark Vietnamese, marking a\\nsignificant advancement in the Vietnamese AI landscape and offering a versatile resource for various\\napplications.\\n1 Introduction\\nThe surge in Large Language Models (LLMs) such as ChatGPT and GPT-4 has significantly advanced\\nthe field of artificial intelligence (AI), particularly in language processing. In 2023, Vietnam’s AI'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# Đẩy dữ liệu từ documents split lên context của synthetic prompt"],"metadata":{"id":"6ymjM70lic30"}},{"cell_type":"code","source":["gen_prompt = synthetic_prompt.format(context=splits[0].page_content, context2=splits[1].page_content)"],"metadata":{"id":"FMZGx5CEiPbn","executionInfo":{"status":"ok","timestamp":1730058737680,"user_tz":-420,"elapsed":370,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["print(gen_prompt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iBuVjUHMiTNU","executionInfo":{"status":"ok","timestamp":1730058747748,"user_tz":-420,"elapsed":404,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"b170720c-fdb8-45ae-ea25-e9613bb7a56a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Bạn sẽ được cung cấp với một đoạn văn bản. Nhiệm vụ của bạn là hãy dựa trên nội dung này và tạo ra 20 cặp câu hỏi theo dạng FAQ mà một người bình thường sẽ hỏi:\n","---CONTEXT---\n","VinaLLaMA: LLaMA-based Vietnamese Foundation Model\n","Quan Nguyen∗, Huy Pham and†Dung Dao‡\n","December 19, 2023\n","Abstract\n","In this technical report, we present VinaLLaMA, an open-weight, state-of-the-art (SOTA)\n","Large Language Model for the Vietnamese language, built upon LLaMA-2 with an additional\n","800 billion trained tokens. VinaLLaMA not only demonstrates fluency in Vietnamese but also\n","exhibits a profound understanding of Vietnamese culture, making it a truly indigenous model.\n","VinaLLaMA-7B-chat, trained on 1 million high-quality synthetic samples, achieves SOTA results\n","on key benchmarks, including VLSP, VMLU, and Vicuna Benchmark Vietnamese, marking a\n","significant advancement in the Vietnamese AI landscape and offering a versatile resource for various\n","applications.\n","1 Introduction\n","The surge in Large Language Models (LLMs) such as ChatGPT and GPT-4 has significantly advanced\n","the field of artificial intelligence (AI), particularly in language processing. In 2023, Vietnam’s AI\n","---END---\n","Bạn hãy tạo ra 10 cặp câu hỏi bằng Tiếng Việt theo dạng FAQ mà một người bình thường sẽ hỏi với format như sau:\n","---FORMAT INSTRUCTION---\n","Question:\n","<question1>\n","Answer:\n","<answer1>\n","\n","Question:\n","<question2>\n","Answer:\n","<answer2>\n","... do this 10 times\n","---END---\n","Now, let's start\n","---START---\n","\n"]}]},{"cell_type":"markdown","source":["# Khởi tạo GROQ"],"metadata":{"id":"3kfKSS_IkH0B"}},{"cell_type":"code","source":["from groq import Groq\n","from google.colab import userdata\n","\n","userdata.get('GROQ_API_KEY')\n","llm = Groq(api_key=userdata.get('GROQ_API_KEY'))\n"],"metadata":{"id":"NGVjGJHfivph","executionInfo":{"status":"ok","timestamp":1730059026246,"user_tz":-420,"elapsed":2990,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# Tạo synthetic data từ GROQ"],"metadata":{"id":"5eu488VLkMET"}},{"cell_type":"code","source":["list_qa_question = []\n","for split in splits[10:20]:\n","  gen_prompt = synthetic_prompt.format(context=split.page_content)\n","  response = llm.chat.completions.create(model='llama3-70b-8192',\n","              messages=[{\"role\": \"user\", \"content\": gen_prompt}],\n","              temperature=0.1,)\n","\n","  list_qa_question.append(response)"],"metadata":{"id":"rRUmyaM2jWf8","executionInfo":{"status":"ok","timestamp":1730059216706,"user_tz":-420,"elapsed":56420,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["len(list_qa_question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xb1JmgCMj8io","executionInfo":{"status":"ok","timestamp":1730059218115,"user_tz":-420,"elapsed":15,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"cbbc3005-200b-41e0-fe7b-044a4ffc5cc7"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["list_qa_question[1].choices[0].message"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wk6NxWRGj_lt","executionInfo":{"status":"ok","timestamp":1730059342711,"user_tz":-420,"elapsed":462,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"59ad383e-d721-427d-b169-1c4e156e1d1d"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatCompletionMessage(content='Here are 10 FAQ pairs in Vietnamese based on the provided context:\\n\\n---FAQ---\\n\\nQuestion:\\nMô hình ngôn ngữ nào đã được đào tạo trong bốn kỷ nguyên?\\nAnswer:\\nMột mô hình ngôn ngữ cơ sở tiên tiến cho ngôn ngữ Việt Nam đã được đào tạo trong bốn kỷ nguyên.\\n\\nQuestion:\\nMô hình VinaLLaMA-2.7B là gì?\\nAnswer:\\nVinaLLaMA-2.7B là một biến thể mô hình nhỏ hơn với 2,7 tỷ tham số, được tạo ra bằng cách áp dụng quy trình cắt tỉa cấu trúc cho mô hình gốc.\\n\\nQuestion:\\nTại sao lại cần cắt tỉa mô hình?\\nAnswer:\\nCắt tỉa mô hình giúp giảm kích thước mô hình mà vẫn giữ lại các chức năng cốt lõi của nó.\\n\\nQuestion:\\nPhương pháp đào tạo nào đã được sử dụng cho mô hình 2.7B?\\nAnswer:\\nPhương pháp đào tạo giám sát giống nhau đã được sử dụng cho mô hình 2.7B và mô hình 7B.\\n\\nQuestion:\\nThời gian đào tạo mô hình là bao lâu?\\nAnswer:\\nGiai đoạn đào tạo trước đã được hoàn thành trong một tuần, trong khi giai đoạn đào tạo tinh chỉnh đã được hoàn thành nhanh hơn.\\n\\nQuestion:\\nLoại máy tính nào đã được sử dụng cho giai đoạn đào tạo trước?\\nAnswer:\\nMột cụm gồm tám nút, mỗi nút được trang bị 8 bộ xử lý Intel Habana Gaudi2, đã được sử dụng cho giai đoạn đào tạo trước.\\n\\nQuestion:\\nLoại máy tính nào đã được sử dụng cho giai đoạn đào tạo tinh chỉnh?\\nAnswer:\\nMột nút của Google Cloud TPU v5e đã được sử dụng cho giai đoạn đào tạo tinh chỉnh.\\n\\nQuestion:\\nTại sao lại cần sử dụng nhiều máy tính khác nhau cho các giai đoạn đào tạo?\\nAnswer:\\nSử dụng nhiều máy tính khác nhau giúp tăng tốc độ đào tạo và giảm thời gian đào tạo.\\n\\nQuestion:\\nMô hình ngôn ngữ nào đã được tạo ra sau khi đào tạo?\\nAnswer:\\nMột mô hình ngôn ngữ cơ sở tiên tiến cho ngôn ngữ Việt Nam đã được tạo ra sau khi đào tạo.\\n\\nQuestion:\\nTại sao lại cần tạo ra một mô hình ngôn ngữ riêng cho tiếng Việt?\\nAnswer:\\nTạo ra một mô hình ngôn ngữ riêng cho tiếng Việt giúp cải thiện độ chính xác và hiệu suất của mô hình trong việc xử lý ngôn ngữ này.', role='assistant', function_call=None, tool_calls=None)"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# Format lại câu hỏi và câu trả lời"],"metadata":{"id":"LIdx6l-mmLLN"}},{"cell_type":"code","source":["text = '''\n","Question:\\nMô hình ngôn ngữ nào đã được đào tạo trong bốn kỷ nguyên?\\nAnswer:\\nMột mô hình ngôn ngữ cơ sở tiên tiến cho ngôn ngữ Việt Nam đã được đào tạo trong bốn kỷ nguyên.\n","'''\n","text = text.split('Question:\\n')[1:]\n","for sentence in text:\n","  question_part, answer_part = sentence.split('\\nAnswer:\\n')\n","  print(f'Question: {question_part}')\n","  print(f'Answer:  {answer_part}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1R5_vQ6llxM8","executionInfo":{"status":"ok","timestamp":1730059728506,"user_tz":-420,"elapsed":365,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"47aa658c-446e-40dc-df79-3b98452529e5"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Question: Mô hình ngôn ngữ nào đã được đào tạo trong bốn kỷ nguyên?\n","Answer:  Một mô hình ngôn ngữ cơ sở tiên tiến cho ngôn ngữ Việt Nam đã được đào tạo trong bốn kỷ nguyên.\n","\n"]}]},{"cell_type":"code","source":["def parse_qa_pairs(text):\n","    \"\"\"\n","    Parses a given text containing questions and answers into a list of dictionaries.\n","\n","    Parameters:\n","    - text (str): A string containing questions and answers in a structured format.\n","\n","    Returns:\n","    - List[Dict[str, str]]: A list of dictionaries, each representing a question-answer pair.\n","    \"\"\"\n","    qa_pairs_simplified = []\n","\n","    # Split the text based on \"Question:\" as a delimiter and ignore the first split which is empty\n","    sections = text.split(\"Question:\\n\")[1:]\n","\n","    for section in sections:\n","        # Each section contains one question and one answer split by \"Answer:\"\n","        question_part, answer_part = section.split(\"\\nAnswer:\\n\")\n","        question = question_part.strip()\n","        answer = answer_part.strip()\n","        qa_pairs_simplified.append({\"question\": question, \"answer\": answer})\n","\n","    return qa_pairs_simplified"],"metadata":{"id":"WibB7beKkRCB","executionInfo":{"status":"ok","timestamp":1730059735599,"user_tz":-420,"elapsed":362,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["qa = []\n","for qa_pair in list_qa_question:\n","  pair = qa_pair.choices[0].message.content\n","  qa.append(parse_qa_pairs(pair))"],"metadata":{"id":"5kTwCkeplqzK","executionInfo":{"status":"ok","timestamp":1730059857284,"user_tz":-420,"elapsed":357,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["print(qa[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N9QbmcjkmoTI","executionInfo":{"status":"ok","timestamp":1730059884305,"user_tz":-420,"elapsed":549,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"c20ce4e7-589e-411e-e005-07f7581598f2"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'question': 'Mục đích của giai đoạn thứ hai trong việc tạo dữ liệu tổng hợp là gì?', 'answer': 'Mục đích của giai đoạn thứ hai là để tiết kiệm chi phí trong khi vẫn duy trì hiệu suất giống nhau với quá trình chưng cất từ GPT-4.'}, {'question': 'Vietcuna-3B-v2 được sử dụng để làm gì?', 'answer': 'Vietcuna-3B-v2 được triển khai để tiết kiệm chi phí trong khi vẫn duy trì hiệu suất giống nhau với quá trình chưng cất từ GPT-4.'}, {'question': 'Tại sao lại cần có 500,000 mẫu tiếng Việt tổng hợp?', 'answer': '500,000 mẫu tiếng Việt tổng hợp được tạo ra để tăng cường dữ liệu và phát triển mô hình ngôn ngữ song ngữ.'}, {'question': 'Ngoài các mẫu tiếng Việt, còn có thêm các mẫu tiếng Anh nào khác?', 'answer': 'Ngoài các mẫu tiếng Việt, còn có thêm 500,000 mẫu tiếng Anh được lấy từ các bộ dữ liệu OpenHermes-2.5 và Capybara.'}, {'question': 'Tại sao lại cần có các mẫu tiếng Anh?', 'answer': 'Các mẫu tiếng Anh được thêm vào để tăng cường dữ liệu và phát triển mô hình ngôn ngữ song ngữ.'}, {'question': 'Bộ dữ liệu cuối cùng bao gồm những loại nhiệm vụ nào?', 'answer': 'Bộ dữ liệu cuối cùng bao gồm các loại nhiệm vụ như lý luận, đóng vai, viết thơ, lập trình, gọi hàm và nhắc nhở tác nhân.'}, {'question': 'Tại sao lại cần có nhiều loại nhiệm vụ khác nhau trong bộ dữ liệu?', 'answer': 'Nhiều loại nhiệm vụ khác nhau trong bộ dữ liệu được thiết kế để đảm bảo mô hình ngôn ngữ cuối cùng có khả năng rộng rãi.'}, {'question': 'Nous Research có vai trò gì trong dự án này?', 'answer': 'Nous Research đã hợp tác với chúng tôi để tạo ra các mẫu tiếng Việt và tiếng Anh tổng hợp.'}, {'question': 'Tại sao lại cần có một mô hình ngôn ngữ song ngữ?', 'answer': 'Một mô hình ngôn ngữ song ngữ được phát triển để có thể xử lý và hiểu cả hai ngôn ngữ tiếng Việt và tiếng Anh.'}, {'question': 'Quá trình fine-tuning được thực hiện như thế nào?', 'answer': 'Quá trình fine-tuning được thực hiện đầy đủ trên mô hình ngôn ngữ sau khi đã có bộ dữ liệu cuối cùng.'}]\n"]}]},{"cell_type":"markdown","source":["# Chuyển định dạng về dạng ShareGPT để finetuning"],"metadata":{"id":"0KiTYVihmw-A"}},{"cell_type":"code","source":["sharegpt_data = []\n","for group in qa:\n","  for pair in group:\n","    convo = {}\n","    convo['conversations'] = [{\"from\": \"human\", \"value\": pair['question']}, {\"from\": \"gpt\", \"value\": pair['answer']}]\n","    sharegpt_data.append(convo)"],"metadata":{"id":"Bj0nu33UmpV1","executionInfo":{"status":"ok","timestamp":1730059962144,"user_tz":-420,"elapsed":365,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["sharegpt_data[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ppjwJq-JnAOR","executionInfo":{"status":"ok","timestamp":1730059974608,"user_tz":-420,"elapsed":463,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"7cb6903d-c91b-40fc-d6b4-a4bf219be4c7"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'conversations': [{'from': 'human',\n","   'value': 'Mục đích của giai đoạn thứ hai trong việc tạo dữ liệu tổng hợp là gì?'},\n","  {'from': 'gpt',\n","   'value': 'Mục đích của giai đoạn thứ hai là để tiết kiệm chi phí trong khi vẫn duy trì hiệu suất giống nhau với quá trình chưng cất từ GPT-4.'}]}"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# Lưu lại file sharegpt\n","\n","import json\n","\n","with open('sharegpt_data.json', 'w', encoding='utf-8') as f:\n","  json.dump(sharegpt_data, f, indent=4, ensure_ascii=False)"],"metadata":{"id":"LolWK5hanDMp","executionInfo":{"status":"ok","timestamp":1730060043883,"user_tz":-420,"elapsed":383,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["import datasets\n","\n","dataset = datasets.load_dataset('json', data_files='sharegpt_data.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["cab83240202b41eea376a511ef7f4199","838b873ab8124dde888d5f18658371c7","e26eec2557cd4fe98d77b078a32cc2b7","2373325ca01c42d5aacf48d00c830aca","6f64822857cc428da4a5adbb2dc610cf","eacb700bf9c446fba04b01bf8596c273","1ea59cb4c4034f0f95658a0e990993bf","092716b7e4b9451f8cb108042e9801db","fe24851f00dc45f5a1acec062c1e5bbc","0850909617b94bde80ce36644ba52a1b","ca98787ce6a44e809a3da6ad7e584021"]},"id":"CmeRPuDanUK7","executionInfo":{"status":"ok","timestamp":1730060062015,"user_tz":-420,"elapsed":5464,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"}},"outputId":"cacc7967-a736-40c2-e74b-a0e8f61eae40"},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cab83240202b41eea376a511ef7f4199"}},"metadata":{}}]}]}